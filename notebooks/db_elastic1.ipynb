{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c007e484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting genai_utils/db_elastic1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile \"genai_utils/db_elastic1.py\"\n",
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "RUN as 'python -m genai_utils.db_elastic1 \"\n",
    "'''\n",
    "\n",
    "import os,glob\n",
    "from mangorest.mango import webapi\n",
    "from ray import logger\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "BASE = \"~/data/gpt/\"\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_elasticsearch import (\n",
    "    BM25Strategy,\n",
    "    DenseVectorStrategy,\n",
    "    ElasticsearchStore,\n",
    ")\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Elastic search parameters\n",
    "#\n",
    "ES_URL, ES_USER, ES_PW  = \"http://localhost:9200\", \"elastic\", \"elastic\"\n",
    "ES_CNX   = dict(es_url= ES_URL, es_user= ES_USER, es_password=ES_PW)\n",
    "_ES_STARTEGIES = {\n",
    "    \"hnsw\":     DenseVectorStrategy(), \n",
    "    \"bm25\":     BM25Strategy(),\n",
    "    \"hybrid\":   DenseVectorStrategy(hybrid=True, rrf=False),\n",
    "    \"sparse\":   None,\n",
    "    \"exact\":    None,\n",
    "}\n",
    "# ---------------------------------------------------------------------------------------\n",
    "# Embeddings - lets use local emebddings\n",
    "#\n",
    "def getEmbedding(model=\"all-minilm:L6-v2\",base_url = \"http://127.0.0.1:11434/\"):\n",
    "    e = OllamaEmbeddings( model = model, base_url =base_url )\n",
    "    return e\n",
    "\n",
    "class Elastic:\n",
    "    def __init__(self, es_cnx=ES_CNX, index=\"sageai\", strategy=\"hnsw\", embed=\"all-minilm:L6-v2\"):\n",
    "        self.es_cnx, self.index, self. strategy, self.embed  = es_cnx, index, strategy, embed\n",
    "        if type(self.embed) == str:\n",
    "            self.embed = getEmbedding(embed)\n",
    "            \n",
    "        self.strategy = _ES_STARTEGIES[self.strategy]\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    def _getChunks(self, file=f\"{BASE}HS4_SGS1_V1S2.pdf\", chunk_overlap_ratio=0.2, chunk_size=8000):\n",
    "        from rag_basic.process_files import multi_process_pdf,process_pdf_to_chunks\n",
    "        if ( file.endswith(\".pdf\")):\n",
    "            chunks = process_pdf_to_chunks(file)        \n",
    "        elif( file.endswith(\".txt\")):\n",
    "            with open(file, \"r\", encoding=\"utf-8\", errors='ignore') as f:\n",
    "                text = f.read()\n",
    "                \n",
    "            from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "            text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=chunk_size,\n",
    "                chunk_overlap= int(chunk_overlap_ratio * chunk_size),\n",
    "                add_start_index=True,\n",
    "            )\n",
    "            texts = text_splitter.split_text(text)\n",
    "            chunks = []\n",
    "            for t in texts:\n",
    "                chunks.append(Document( page_content=t,  metadata={\"source\": file}))\n",
    "        else:\n",
    "            assert 0, \"Unknown file type\"\n",
    "        return chunks\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    def indexdoc(self, file=f\"{BASE}HS4_SGS1_V1S2.pdf\", embed=None, strategy=\"hnsw\"):\n",
    "        file = os.path.expanduser(file)\n",
    "        chunks = self._getChunks(file)\n",
    "\n",
    "        for i in range(0, len(chunks), 20000):\n",
    "            vectorstore = ElasticsearchStore.from_documents(\n",
    "                documents= chunks[i : min(i + 20000, len(chunks))],\n",
    "                embedding=self.embed,\n",
    "                **self.es_cnx,\n",
    "                index_name=self.index,\n",
    "                bulk_kwargs={\n",
    "                    \"chunk_size\": 100,\n",
    "                },\n",
    "                strategy=self.strategy,\n",
    "            )\n",
    "        \n",
    "        print(f\"Indexed {len(chunks)} chunks from {file}\")\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    def es_retriever( self, k= 10 ):\n",
    "        v = ElasticsearchStore( **self.es_cnx, embedding=self.embed, index_name=self.index, strategy=self.strategy)\n",
    "        return v.as_retriever(search_kwargs={\"k\": k})\n",
    "\n",
    "    # ---------------------------------------------------------------------------------------\n",
    "    def search(self,query, k=10, rerank=1, **kwargs):\n",
    "        docs = self.es_retriever().invoke(query)\n",
    "\n",
    "        h = {r.page_content: r for r in docs}\n",
    "        if len(h) != len(docs):\n",
    "            docs = [v for v in h.values()]\n",
    "        \n",
    "        ret = []\n",
    "        for d in docs:\n",
    "            ret.append(dict(page_content=d.page_content, metadata=d.metadata))\n",
    "        return ret\n",
    "\n",
    "def indexFolder(folder=\".\", recursive=1):\n",
    "    folder = os.path.expanduser((folder))\n",
    "    logger.info(f\"Indexing {folder}\")\n",
    "    se = Elastic()\n",
    "    files = [f for f in glob.glob(folder, recursive=recursive) if os.path.isfile(f)]\n",
    "    for f in files:\n",
    "        print(f\"{os.path.getsize(f)} : {f} \")\n",
    "        se.indexdoc(f)\n",
    "        \n",
    "from colabexts import utils as colabexts_utils\n",
    "if __name__ == '__main__' and not colabexts_utils.inJupyter():\n",
    "    folder = \".\" if len(sys.args) <= 1 else sys.args[1]\n",
    "    logger.info(f\"Indexing  {folder}\")\n",
    "    indexFolder(folder)\n",
    "\n",
    "\n",
    "def test():\n",
    "    se = Elastic()\n",
    "    docs = se.search(\"tell me about Ka-band - where do they play\")\n",
    "    return docs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420964da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
