{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple JSON DB - made for simple editing before moving to serious DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "jpath=os.path.dirname(colabexts.__file__)\n",
    "jcom = f'{jpath}/jcommon.ipynb'\n",
    "%run $jcom\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 8)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /opt/utils/geo_utils/services/gen/myjson.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile  ../jsondb.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "GENERATED FROM aiservices/notebooks/db/myjson.ipynb\n",
    "'''\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "import os, sys, datetime, re, json, shutil, glob, traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(\"/opt/utils\")\n",
    "from colabexts import utils as colabexts_utils\n",
    "from collections import defaultdict \n",
    "from mangorest import mango\n",
    "from inspect import isfunction\n",
    "\n",
    "import logging\n",
    "\n",
    "# Remove all handlers associated with the root logger object.\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig( level=logging.INFO,\n",
    "        format='%(levelname)s:%(name)s %(asctime)s %(filename)s:%(lineno)s:%(funcName)s: %(message)s',\n",
    "        #format='%(asctime)s %(name)s %(levelname)s: %(message)s',\n",
    "        handlers=[ logging.FileHandler(\"/tmp/app.log\"), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger( \"geoapp\" )\n",
    "\n",
    "\n",
    "class myjson:\n",
    "    def __init__(self, db=\"default\", base=os.path.expanduser(\"~/myjson\")):\n",
    "        self.base = os.path.expanduser(base)\n",
    "        self.db = db\n",
    "        self.createdb( db )\n",
    "\n",
    "    def createdb(self, db):\n",
    "        db = self.base + \"/\" + db\n",
    "        os.makedirs(db, exist_ok=True)\n",
    "        self.db = db\n",
    "        logger.debug(f\"Current DB {self.db}\")\n",
    "        #traceback.print_stack()\n",
    "        return self.db\n",
    "\n",
    "    def changedb(self, db):\n",
    "        createdb(db)\n",
    "\n",
    "    def deletedb(self, db):\n",
    "        if (db == \"default\"):\n",
    "            logger.warning(f\"Cannot Delete default DB\")\n",
    "            return\n",
    "\n",
    "        db = self.base + \"/\" + db\n",
    "        logger.info(f\"Deleting DB {db}: {db}\")\n",
    "        shutil.rmtree(db)\n",
    "        if self.db == db:\n",
    "            createdb(\"default\")\n",
    "\n",
    "        return self.db\n",
    "        \n",
    "\n",
    "    def listDbs(self):\n",
    "        dbs = [os.path.basename(c[0:-1]) for c in glob.glob(f\"{self.base}/*/\", recursive=True)]\n",
    "        return dbs\n",
    "\n",
    "    def listTables(self):\n",
    "        dbs = [os.path.basename(c[0:-1]) for c in glob.glob(f\"{self.db}/*/\", recursive=True)]\n",
    "        return dbs\n",
    "\n",
    "    def create_table(self, table):\n",
    "        tab = self.db + \"/\" + table \n",
    "        os.makedirs(tab, exist_ok=True)\n",
    "        return tab\n",
    "\n",
    "    def delete_table(self, table):\n",
    "        tab = self.db + \"/\" + table \n",
    "        if ( os.path.exists(tab)):\n",
    "            shutil.rmtree(tab)\n",
    "        return tab\n",
    "\n",
    "    def _update_info(self, df, table, max_id):\n",
    "        if ( len(df) <= 0):\n",
    "            return\n",
    "            \n",
    "        info_file = f\"{self.db}/{table}/info.js\"\n",
    "        infoj = dict(columns=[c for c in df.columns], maxid=max_id, nrows=len(df))\n",
    "        open(info_file, \"w\").write(json.dumps(infoj, indent=2))\n",
    "\n",
    "        #infoj = colabexts_utils.parsej(open(info_file).read())\n",
    "        return infoj\n",
    "        \n",
    "    def fromDataFrame(self, df, table, delete=True):\n",
    "        if (delete):\n",
    "           self.delete_table(table) \n",
    "        tab = self.create_table(table)\n",
    "        for rowid, r in df.iterrows():\n",
    "            d = r.to_dict()\n",
    "            d['rowid'] = rowid\n",
    "            open(f\"{tab}/{rowid}.json\", \"w\").write( json.dumps(d, indent=2))\n",
    "        \n",
    "    def get(self, table, rowid=None ):\n",
    "        if ( not rowid):\n",
    "            return self.read(table)\n",
    "\n",
    "        f = f\"{self.db}/{table}/{rowid}.json\"\n",
    "        if ( not os.path.isfile(f)):\n",
    "            return None\n",
    "        r = open(f).read()\n",
    "        a = colabexts_utils.parsej(r)\n",
    "        return a;\n",
    "\n",
    "    def read(self, table, nrows=1024*1024, filter=None , **kwargs):\n",
    "        rows, cols, max_id =[], {}, 0\n",
    "\n",
    "        dir = f\"{self.db}/{table}/*.json\"\n",
    "\n",
    "        #logger.debug(f\"Reading from {dir}\")\n",
    "\n",
    "        sortk =  lambda x: int(os.path.basename(x).split('.')[0])\n",
    "        if ( nrows and nrows < 0):\n",
    "            nrows = -nrows\n",
    "            files = sorted(glob.glob(dir), key=sortk , reverse=True)\n",
    "        else:\n",
    "            files = sorted(glob.glob(dir), key=sortk )\n",
    "\n",
    "        for f in files:\n",
    "            try:\n",
    "                r = open(f).read()\n",
    "                a = colabexts_utils.parsej(r)\n",
    "                #a = json.loads(r)\n",
    "                if (\"rowid\" not in a):\n",
    "                    logger.error(f\"ROWID IS MISSING in {f}\")\n",
    "                    #a['rowid'] = os.path.basename(f)[:-5]\n",
    "                    continue; \n",
    "                    \n",
    "                max_id = a['rowid']\n",
    "\n",
    "                if ( filter and type(filter) == dict):\n",
    "                    c = all(a.get(k, None) == v for k, v in filter.items())\n",
    "                    if (not c):\n",
    "                        continue\n",
    "                elif ( filter and isfunction(filter) ):\n",
    "                    c= filter(a)\n",
    "                    if (not c):\n",
    "                        continue\n",
    "\n",
    "                cols.update(a)\n",
    "                rows.append(a)\n",
    "            except Exception as e:\n",
    "                logger.error(e)\n",
    "                out = \"\"\n",
    "                for i, l in enumerate(r.split(\"\\n\")[:100]):\n",
    "                    out += f'{i+1:3d}: {l}\\n'\n",
    "                logger.error(f\"Error while parsing {f} \\n\\n{out}\")\n",
    "            if ( len(rows) >= nrows):\n",
    "                break;\n",
    "                \n",
    "        df = pd.DataFrame(rows) \n",
    "        if ( not filter):\n",
    "            self._update_info (df, table, max_id,)\n",
    "        return df\n",
    "\n",
    "    def delete(self, table, rowid, **kwargs):\n",
    "        print(f'''\n",
    "        **** DELETING {table} {rowid}\n",
    "        **** \n",
    "        ****\n",
    "        ''')\n",
    "        f = f\"{self.db}/{table}/{rowid}.json\"\n",
    "        if ( not os.path.isfile(f)):\n",
    "            return 0\n",
    "        os.rename(f, f+\".deleted\")\n",
    "        pass;\n",
    "\n",
    "\n",
    "    def update(self, table, data):\n",
    "        ret = data\n",
    "        if type(data) == str:\n",
    "            ret = colabexts_utils.parsej(data)\n",
    "        elif type(data) == pd.Series:\n",
    "            ret = data.to_dict()\n",
    "            \n",
    "        tab = self.db + \"/\" + table \n",
    "\n",
    "        rowid = ret.get(\"rowid\", None)\n",
    "        if ( rowid is None or not str(rowid) or int(rowid) < 0 ):\n",
    "            rowid = max([-1] +[int(os.path.basename(c[:-5])) for c in glob.glob(f\"{tab}/*.json\")])\n",
    "            rowid = rowid + 1\n",
    "            logger.info(f\"Update called with no rowid: Assuming insert => newId= {rowid}\")\n",
    "            ret['rowid'] = rowid\n",
    "            \n",
    "        rowid = ret[\"rowid\"]\n",
    "        row = f\"{tab}/{rowid}.json\"\n",
    "        \n",
    "        if ( os.path.exists(row)):\n",
    "            old = colabexts_utils.parsej((open( row, \"r\")).read())\n",
    "            old.update(ret)\n",
    "            ret = old\n",
    "            \n",
    "        open(f\"{tab}/{rowid}.json\", \"w\").write( json.dumps(ret, cls=mango.myEncoder, indent=2))\n",
    "\n",
    "        return ret\n",
    "        \n",
    "        \n",
    "\n",
    "#db = myjson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 06:47:59,740 app.mangorest INFO: \n",
      "************************ MANGO REST API 2.0*************************\n",
      "\n",
      "2024-06-21 06:47:59,745 geoapp INFO: Current database /Users/snarayan/myjson/default\n",
      "2024-06-21 06:47:59,746 geoapp INFO: Current database /opt/data/tseries/data/_MONITORING\n",
      "2024-06-21 06:47:59,748 geoapp INFO: Reading from /opt/data/tseries/data/_MONITORING/schedules/*.json\n",
      "2024-06-21 06:47:59,753 geoapp INFO: Reading from /opt/data/tseries/data/_MONITORING/schedules/*.json\n",
      "2024-06-21 06:47:59,757 geoapp ERROR: unterminated string literal (detected at line 26) (<string>, line 26)\n",
      "2024-06-21 06:47:59,759 geoapp ERROR: Error while parsing /opt/data/tseries/data/_MONITORING/schedules/18.json \n",
      "\n",
      "  1: {\n",
      "  2:   \"rowid\": 18,\n",
      "  3:   \"active\": \"1\",\n",
      "  4:   \"sname\": \"check_url\",\n",
      "  5:   \"description\": \"Asthma alert monitoring system1\",\n",
      "  6:   \"scheduled_time\": \"*/30 * * * *\",\n",
      "  7:   \"inactive_time\": \"\",\n",
      "  8:   \"on_begin\": \"\",\n",
      "  9:   \"trigger\": \"check_url\",\n",
      " 10:   \"parameters\": \"http://www.microsoft1.com\",\n",
      " 11:   \"notifications_interval\": \"12*60\",\n",
      " 12:   \"email\": \"to: cc@test.com,dd@test.com;\\r\\ncc: sada@geospaces.org;\\r\\nbcc: cc@test.com,cc@test.com\",\n",
      " 13:   \"mshook\": \"\",\n",
      " 14:   \"action_script\": \"\",\n",
      " 15:   \"message_template\": \"Subject: Test message\\r\\n\\r\\nHello, \\r\\nIgnore this message - this is a test.  {parameters} tested\\r\\nAn alert is created @{datetime.datetime.now()} from {name} \",\n",
      " 16:   \"user\": \"sada\",\n",
      " 17:   \"name\": \"check_url\",\n",
      " 18:   \"jobid\": 4,\n",
      " 19:   \"status\": \"Running@2024-05-27 15:00:00.025693\",\n",
      " 20:   \"wait\": 1187.324834,\n",
      " 21:   \"runat\": \"2024-05-27 15:00:00.000766\",\n",
      " 22:   \"pid\": 22894,\n",
      " 23:   \"ppid\": 12141,\n",
      " 24:   \"host\": \"sada-mac.local\",\n",
      " 25:   \"start\": \"2024-05-27 15:00:00.025693\"\n",
      " 26: }-27 15:00:00.025575\"\n",
      " 27: }\n",
      "\n",
      "2024-06-21 06:47:59,761 geoapp ERROR: unmatched '}' (<string>, line 29)\n",
      "2024-06-21 06:47:59,762 geoapp ERROR: Error while parsing /opt/data/tseries/data/_MONITORING/schedules/19.json \n",
      "\n",
      "  1: {\n",
      "  2:   \"rowid\": 19,\n",
      "  3:   \"active\": \"1\",\n",
      "  4:   \"sname\": \"test\",\n",
      "  5:   \"description\": \"test\",\n",
      "  6:   \"scheduled_time\": \"*/30 * * * *\",\n",
      "  7:   \"inactive_time\": \"\",\n",
      "  8:   \"on_begin\": \"\",\n",
      "  9:   \"trigger\": \"check_custom\",\n",
      " 10:   \"parameters\": \"\",\n",
      " 11:   \"notifications_interval\": \"4*60\",\n",
      " 12:   \"email\": \"to: cc@test.com,dd@test.com;\\r\\ncc: cc@test.com;\\r\\nbcc: cc@test.com,cc@test.com\",\n",
      " 13:   \"mshook\": \"\",\n",
      " 14:   \"action_script\": \"\",\n",
      " 15:   \"message_template\": \"Subject: Test message\\r\\n\\r\\nHello, \\r\\nIgnore this message - this is a test. An alert is created @{datetime.datetime.now()} from {name} \",\n",
      " 16:   \"user\": \"sada\",\n",
      " 17:   \"jobid\": 5,\n",
      " 18:   \"status\": \"Scheduled@2024-05-27 15:00:00.000886\",\n",
      " 19:   \"wait\": 1038.917233,\n",
      " 20:   \"runat\": \"2024-05-27 15:00:00.000886\",\n",
      " 21:   \"pid\": 23535,\n",
      " 22:   \"ppid\": 12141,\n",
      " 23:   \"host\": \"sada-mac.local\"\n",
      " 24: }17327,\n",
      " 25:   \"runat\": \"2024-05-27 15:00:00.000938\",\n",
      " 26:   \"pid\": 23534,\n",
      " 27:   \"ppid\": 12141,\n",
      " 28:   \"host\": \"sada-mac.local\"\n",
      " 29: }\n",
      "\n",
      "2024-06-21 06:47:59,768 geoapp ERROR: unterminated string literal (detected at line 25) (<string>, line 25)\n",
      "2024-06-21 06:47:59,769 geoapp ERROR: Error while parsing /opt/data/tseries/data/_MONITORING/schedules/36.json \n",
      "\n",
      "  1: {\n",
      "  2:   \"rowid\": 36,\n",
      "  3:   \"active\": \"1\",\n",
      "  4:   \"sname\": \"check_url\",\n",
      "  5:   \"description\": \"Asthma alert monitoring system1\",\n",
      "  6:   \"scheduled_time\": \"*/30 * * * *\",\n",
      "  7:   \"inactive_time\": \"\",\n",
      "  8:   \"on_begin\": \"\",\n",
      "  9:   \"trigger\": \"check_url\",\n",
      " 10:   \"parameters\": \"http://www.geospaces1.org\",\n",
      " 11:   \"notifications_interval\": \"12*60\",\n",
      " 12:   \"email\": \"to: cc@test.com,dd@test.com;\\r\\ncc: sada@geospaces.org;\\r\\nbcc: cc@test.com,cc@test.com\",\n",
      " 13:   \"mshook\": \"\",\n",
      " 14:   \"action_script\": \"fix_url.py\",\n",
      " 15:   \"message_template\": \"Date: {datetime.datetime.now()} \\r\\nSubject: Checking the URL {parameters}\\r\\n\\r\\nHello, \\r\\nChecking for {parameters}.\\r\\nSeems to be an issue - will run  {action_script}\\r\\n\\r\\n\\r\\n\",\n",
      " 16:   \"user\": \"sada\",\n",
      " 17:   \"name\": \"check_url\",\n",
      " 18:   \"jobid\": 4,\n",
      " 19:   \"status\": \"Scheduled@2024-06-21 06:30:00.001284\",\n",
      " 20:   \"wait\": 1383.104972,\n",
      " 21:   \"runat\": \"2024-06-21 06:30:00.001284\",\n",
      " 22:   \"pid\": 24812,\n",
      " 23:   \"ppid\": 24807,\n",
      " 24:   \"host\": \"sada-mac.local\"\n",
      " 25: }d\": 24811,\n",
      " 26:   \"ppid\": 24807,\n",
      " 27:   \"host\": \"sada-mac.local\"\n",
      " 28: }\n",
      "\n",
      "2024-06-21 06:47:59,772 geoapp ERROR: unmatched '}' (<string>, line 29)\n",
      "2024-06-21 06:47:59,773 geoapp ERROR: Error while parsing /opt/data/tseries/data/_MONITORING/schedules/41.json \n",
      "\n",
      "  1: {\n",
      "  2:   \"rowid\": 41,\n",
      "  3:   \"active\": \"1\",\n",
      "  4:   \"sname\": \"run_model\",\n",
      "  5:   \"description\": \"Running the model\",\n",
      "  6:   \"scheduled_time\": \"0 0  * * *\",\n",
      "  7:   \"inactive_time\": \"\",\n",
      "  8:   \"on_begin\": \"\",\n",
      "  9:   \"trigger\": \"run_model\",\n",
      " 10:   \"parameters\": \"{model: model_name, \\r\\n data_src: '_ALLDATA.parquet' }\",\n",
      " 11:   \"notifications_interval\": \"12*60\",\n",
      " 12:   \"email\": \"to: cc@test.com,dd@test.com\\r\\ncc: geo1@geospaces.org;\\r\\nbcc: cc@test.com,cc@test.com\",\n",
      " 13:   \"mshook\": \"\",\n",
      " 14:   \"action_script\": \"\",\n",
      " 15:   \"message_template\": \"Subject: Test message\\r\\n\\r\\nHello, \\r\\nIgnore this message - this is a test. An alert is created @{datetime.datetime.now()} from {name} \",\n",
      " 16:   \"user\": \"sada\",\n",
      " 17:   \"name\": \"maverick_alert\",\n",
      " 18:   \"jobid\": 2,\n",
      " 19:   \"status\": \"Scheduled@2024-06-22 00:00:00.000993\",\n",
      " 20:   \"wait\": 63734.907121,\n",
      " 21:   \"runat\": \"2024-06-22 00:00:00.000993\",\n",
      " 22:   \"pid\": 25101,\n",
      " 23:   \"ppid\": 25099,\n",
      " 24:   \"host\": \"sada-mac.local\"\n",
      " 25: }: \"2024-06-22 00:00:00.000959\",\n",
      " 26:   \"pid\": 25102,\n",
      " 27:   \"ppid\": 25099,\n",
      " 28:   \"host\": \"sada-mac.local\"\n",
      " 29: }\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "if \"/opt/utils/geo_utils/\" not in sys.path: sys.path.append(\"/opt/utils/geo_utils/\" )\n",
    "from services.gen.myjson import myjson\n",
    "\n",
    "b = {'rowid': 4,\n",
    " 'active': '1',\n",
    " 'sname': 'check_url',\n",
    " 'test': 0\n",
    " }\n",
    "\n",
    "MYDB   = myjson(base=\"/opt/data/tseries/data\", db='_MONITORING')\n",
    "from inspect import isfunction\n",
    "table = \"schedules\"\n",
    "\n",
    "df = MYDB.read(table, nrows=4, filter= dict(name=\"check_url\") )\n",
    "#display(df)\n",
    "def foo(x):\n",
    "    #print(x, type(x))\n",
    "    #r = x.get('rowid', '') \n",
    "    return 1\n",
    "df1 = MYDB.read(table, filter= lambda x: (int(x['rowid']) == 3) )\n",
    "df1\n",
    "#filter= \n",
    "#isfunction(filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = myjson(db=\"geo\")\n",
    "sch_table = \"schedules\"\n",
    "def insertIntoSchedulerLog(**kwargs):\n",
    "    mydb.update(sch_table, kwargs)\n",
    "    df = mydb.read(sch_table)\n",
    "    return df\n",
    "\n",
    "insertIntoSchedulerLog(a=34, b=75, c=89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39mcreatedb(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m db\u001b[38;5;241m.\u001b[39mlistTables()\n\u001b[1;32m      3\u001b[0m files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/snarayan/myjson/test/test/*.json\u001b[39m\u001b[38;5;124m\"\u001b[39m), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "db.createdb('test')\n",
    "db.listTables()\n",
    "files = sorted(glob.glob(f\"/Users/snarayan/myjson/test/test/*.json\"), reverse=True)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdb\u001b[49m\u001b[38;5;241m.\u001b[39mlistTables()\n\u001b[1;32m      2\u001b[0m db\u001b[38;5;241m.\u001b[39mdeletedb(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m db\u001b[38;5;241m.\u001b[39mdeletedb(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "db.listTables()\n",
    "db.deletedb('default')\n",
    "db.deletedb('test')\n",
    "db.createdb('test')\n",
    "db.create_table('test')\n",
    "db.listTables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( [[\"a\", \"b\"], [\"c\", \"d\"]], columns=[\"col 1\", \"col 2\"] )\n",
    "display(df)\n",
    "db.fromDataFrame(df, \"test\")\n",
    "db.listTables()\n",
    "db.read(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=db.read(\"test\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1, ['col 1']] = \"c_u\"\n",
    "display(df)\n",
    "df.iloc[1].to_json()\n",
    "db.update(\"test\", df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.read(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/opt/utils/\" not in sys.path: sys.path.append(\"/opt/utils/\" )\n",
    "from services.gen.myjson import myjson\n",
    "\n",
    "MYDB   = myjson(base=\"/opt/data/tseries/data\", db='_MONITORING')\n",
    "alerts_table = \"alerts\"\n",
    "\n",
    "a = MYDB.get(alerts_table, rowid=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
