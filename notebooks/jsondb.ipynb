{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple JSON DB - made for simple editing before moving to serious DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import colabexts\n",
    "from colabexts.jcommon import *\n",
    "\n",
    "jpath=os.path.dirname(colabexts.__file__)\n",
    "jcom = f'{jpath}/jcommon.ipynb'\n",
    "%run $jcom\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_rows', 8)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile  genai_utils/jsondb.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "'''\n",
    "'''\n",
    "#----------------------------------------------------------------------------------\n",
    "import os, sys, datetime, re, json, shutil, glob, traceback\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sys.path.append(\"/opt/utils\")\n",
    "from colabexts import utils as colabexts_utils\n",
    "from collections import defaultdict \n",
    "from mangorest import mango\n",
    "from inspect import isfunction\n",
    "\n",
    "import logging\n",
    "\n",
    "# Remove all handlers associated with the root logger object.\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "logging.basicConfig( level=logging.INFO,\n",
    "        format='%(levelname)s:%(name)s %(asctime)s %(filename)s:%(lineno)s:%(funcName)s: %(message)s',\n",
    "        #format='%(asctime)s %(name)s %(levelname)s: %(message)s',\n",
    "        handlers=[ logging.FileHandler(\"/tmp/app.log\"), logging.StreamHandler()],\n",
    ")\n",
    "logger = logging.getLogger( \"genai_utils\" )\n",
    "\n",
    "\n",
    "class myjson:\n",
    "    def __init__(self, db=\"default\", base=os.path.expanduser(\"~/myjson\")):\n",
    "        self.base = os.path.expanduser(base)\n",
    "        self.db = db\n",
    "        self.createdb( db )\n",
    "\n",
    "    def createdb(self, db):\n",
    "        db = self.base + \"/\" + db\n",
    "        os.makedirs(db, exist_ok=True)\n",
    "        self.db = db\n",
    "        logger.debug(f\"Current DB {self.db}\")\n",
    "        #traceback.print_stack()\n",
    "        return self.db\n",
    "\n",
    "    def changedb(self, db):\n",
    "        createdb(db)\n",
    "\n",
    "    def deletedb(self, db):\n",
    "        if (db == \"default\"):\n",
    "            logger.warning(f\"Cannot Delete default DB\")\n",
    "            return\n",
    "\n",
    "        db = self.base + \"/\" + db\n",
    "        logger.info(f\"Deleting DB {db}: {db}\")\n",
    "        shutil.rmtree(db)\n",
    "        if self.db == db:\n",
    "            createdb(\"default\")\n",
    "\n",
    "        return self.db\n",
    "        \n",
    "\n",
    "    def listDbs(self):\n",
    "        dbs = [os.path.basename(c[0:-1]) for c in glob.glob(f\"{self.base}/*/\", recursive=True)]\n",
    "        return dbs\n",
    "\n",
    "    def listTables(self):\n",
    "        dbs = [os.path.basename(c[0:-1]) for c in glob.glob(f\"{self.db}/*/\", recursive=True)]\n",
    "        return dbs\n",
    "\n",
    "    def create_table(self, table):\n",
    "        tab = self.db + \"/\" + table \n",
    "        os.makedirs(tab, exist_ok=True)\n",
    "        return tab\n",
    "\n",
    "    def delete_table(self, table):\n",
    "        tab = self.db + \"/\" + table \n",
    "        if ( os.path.exists(tab)):\n",
    "            shutil.rmtree(tab)\n",
    "        return tab\n",
    "\n",
    "    def _update_info(self, df, table, max_id):\n",
    "        if ( len(df) <= 0):\n",
    "            return\n",
    "            \n",
    "        info_file = f\"{self.db}/{table}/info.js\"\n",
    "        infoj = dict(columns=[c for c in df.columns], maxid=max_id, nrows=len(df))\n",
    "        open(info_file, \"w\").write(json.dumps(infoj, indent=2))\n",
    "\n",
    "        #infoj = colabexts_utils.parsej(open(info_file).read())\n",
    "        return infoj\n",
    "        \n",
    "    def fromDataFrame(self, df, table, delete=True):\n",
    "        if (delete):\n",
    "           self.delete_table(table) \n",
    "        tab = self.create_table(table)\n",
    "        for rowid, r in df.iterrows():\n",
    "            d = r.to_dict()\n",
    "            d['rowid'] = rowid\n",
    "            open(f\"{tab}/{rowid}.json\", \"w\").write( json.dumps(d, indent=2))\n",
    "        \n",
    "    def get(self, table, rowid=None ):\n",
    "        if ( not rowid):\n",
    "            return self.read(table)\n",
    "\n",
    "        f = f\"{self.db}/{table}/{rowid}.json\"\n",
    "        if ( not os.path.isfile(f)):\n",
    "            return None\n",
    "        r = open(f).read()\n",
    "        a = colabexts_utils.parsej(r)\n",
    "        return a;\n",
    "\n",
    "    def read(self, table, nrows=1024*1024, filter=None , **kwargs):\n",
    "        rows, cols, max_id =[], {}, 0\n",
    "\n",
    "        dir = f\"{self.db}/{table}/*.json\"\n",
    "\n",
    "        #logger.debug(f\"Reading from {dir}\")\n",
    "\n",
    "        sortk =  lambda x: int(os.path.basename(x).split('.')[0])\n",
    "        if ( nrows and nrows < 0):\n",
    "            nrows = -nrows\n",
    "            files = sorted(glob.glob(dir), key=sortk , reverse=True)\n",
    "        else:\n",
    "            files = sorted(glob.glob(dir), key=sortk )\n",
    "\n",
    "        for f in files:\n",
    "            try:\n",
    "                r = open(f).read()\n",
    "                a = colabexts_utils.parsej(r)\n",
    "                #a = json.loads(r)\n",
    "                if (\"rowid\" not in a):\n",
    "                    logger.error(f\"ROWID IS MISSING in {f}\")\n",
    "                    #a['rowid'] = os.path.basename(f)[:-5]\n",
    "                    continue; \n",
    "                    \n",
    "                max_id = a['rowid']\n",
    "\n",
    "                if ( filter and type(filter) == dict):\n",
    "                    c = all(a.get(k, None) == v for k, v in filter.items())\n",
    "                    if (not c):\n",
    "                        continue\n",
    "                elif ( filter and isfunction(filter) ):\n",
    "                    c= filter(a)\n",
    "                    if (not c):\n",
    "                        continue\n",
    "\n",
    "                cols.update(a)\n",
    "                rows.append(a)\n",
    "            except Exception as e:\n",
    "                logger.error(e)\n",
    "                out = \"\"\n",
    "                for i, l in enumerate(r.split(\"\\n\")[:100]):\n",
    "                    out += f'{i+1:3d}: {l}\\n'\n",
    "                logger.error(f\"Error while parsing {f} \\n\\n{out}\")\n",
    "            if ( len(rows) >= nrows):\n",
    "                break;\n",
    "                \n",
    "        df = pd.DataFrame(rows) \n",
    "        if ( not filter):\n",
    "            self._update_info (df, table, max_id,)\n",
    "        return df\n",
    "\n",
    "    def delete(self, table, rowid, **kwargs):\n",
    "        print(f'''\n",
    "        **** DELETING {table} {rowid}\n",
    "        **** \n",
    "        ****\n",
    "        ''')\n",
    "        f = f\"{self.db}/{table}/{rowid}.json\"\n",
    "        if ( not os.path.isfile(f)):\n",
    "            return 0\n",
    "        os.rename(f, f+\".deleted\")\n",
    "        pass;\n",
    "\n",
    "\n",
    "    def update(self, table, data):\n",
    "        ret = data\n",
    "        if type(data) == str:\n",
    "            ret = colabexts_utils.parsej(data)\n",
    "        elif type(data) == pd.Series:\n",
    "            ret = data.to_dict()\n",
    "            \n",
    "        tab = self.db + \"/\" + table \n",
    "\n",
    "        rowid = ret.get(\"rowid\", None)\n",
    "        if ( rowid is None or not str(rowid) or int(rowid) < 0 ):\n",
    "            rowid = max([-1] +[int(os.path.basename(c[:-5])) for c in glob.glob(f\"{tab}/*.json\")])\n",
    "            rowid = rowid + 1\n",
    "            logger.info(f\"Update called with no rowid: Assuming insert => newId= {rowid}\")\n",
    "            ret['rowid'] = rowid\n",
    "            \n",
    "        rowid = ret[\"rowid\"]\n",
    "        row = f\"{tab}/{rowid}.json\"\n",
    "        \n",
    "        if ( os.path.exists(row)):\n",
    "            old = colabexts_utils.parsej((open( row, \"r\")).read())\n",
    "            old.update(ret)\n",
    "            ret = old\n",
    "            \n",
    "        open(f\"{tab}/{rowid}.json\", \"w\").write( json.dumps(ret, cls=mango.myEncoder, indent=2))\n",
    "\n",
    "        return ret\n",
    "        \n",
    "#db = myjson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/opt/utils/geo_utils/\" not in sys.path: sys.path.append(\"/opt/utils/geo_utils/\" )\n",
    "from services.gen.myjson import myjson\n",
    "\n",
    "b = {'rowid': 4,\n",
    " 'active': '1',\n",
    " 'sname': 'check_url',\n",
    " 'test': 0\n",
    " }\n",
    "\n",
    "MYDB   = myjson(base=\"/opt/data/tseries/data\", db='_MONITORING')\n",
    "from inspect import isfunction\n",
    "table = \"schedules\"\n",
    "\n",
    "df = MYDB.read(table, nrows=4, filter= dict(name=\"check_url\") )\n",
    "#display(df)\n",
    "def foo(x):\n",
    "    #print(x, type(x))\n",
    "    #r = x.get('rowid', '') \n",
    "    return 1\n",
    "df1 = MYDB.read(table, filter= lambda x: (int(x['rowid']) == 3) )\n",
    "df1\n",
    "#filter= \n",
    "#isfunction(filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = myjson(db=\"geo\")\n",
    "sch_table = \"schedules\"\n",
    "def insertIntoSchedulerLog(**kwargs):\n",
    "    mydb.update(sch_table, kwargs)\n",
    "    df = mydb.read(sch_table)\n",
    "    return df\n",
    "\n",
    "insertIntoSchedulerLog(a=34, b=75, c=89)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.createdb('test')\n",
    "db.listTables()\n",
    "files = sorted(glob.glob(f\"/Users/snarayan/myjson/test/test/*.json\"), reverse=True)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.listTables()\n",
    "db.deletedb('default')\n",
    "db.deletedb('test')\n",
    "db.createdb('test')\n",
    "db.create_table('test')\n",
    "db.listTables()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame( [[\"a\", \"b\"], [\"c\", \"d\"]], columns=[\"col 1\", \"col 2\"] )\n",
    "display(df)\n",
    "db.fromDataFrame(df, \"test\")\n",
    "db.listTables()\n",
    "db.read(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=db.read(\"test\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1, ['col 1']] = \"c_u\"\n",
    "display(df)\n",
    "df.iloc[1].to_json()\n",
    "db.update(\"test\", df.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.read(\"test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if \"/opt/utils/\" not in sys.path: sys.path.append(\"/opt/utils/\" )\n",
    "from services.gen.myjson import myjson\n",
    "\n",
    "MYDB   = myjson(base=\"/opt/data/tseries/data\", db='_MONITORING')\n",
    "alerts_table = \"alerts\"\n",
    "\n",
    "a = MYDB.get(alerts_table, rowid=4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
